{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "import numpy as np\n",
    "import exoplanet as xo\n",
    "import matplotlib.pyplot as pl\n",
    "import theano.tensor as tt\n",
    "import copy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://sohowww.nascom.nasa.gov/data/archive.html\n",
    "blue = fits.open('blue.fits')\n",
    "green = fits.open('green.fits')\n",
    "red = fits.open('red.fits')\n",
    "\n",
    "r, g, b = red[0].data, green[0].data, blue[0].data\n",
    "mask = np.isfinite(r) & np.isfinite(g) & np.isfinite(b)\n",
    "start = blue[0].header['DATES'][0:9]\n",
    "end = blue[0].header['DATES'][14:]\n",
    "start, end = Time([start, end]).jd\n",
    "t = np.linspace(start, end, len(r)) - start\n",
    "r, g, b = r[mask].astype('float64'), g[mask].astype('float64'), b[mask].astype('float64')\n",
    "r, g, b = copy.deepcopy(r), copy.deepcopy(g), copy.deepcopy(b)\n",
    "t = t[mask]\n",
    "flux = np.sum([r, g, b], axis=0)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 58273\n",
    "di = 3000\n",
    "t = t[i:i+di]# * 60\n",
    "\n",
    "add_wn = np.exp(-4)\n",
    "wn = np.random.randn(3, len(t))*add_wn\n",
    "\n",
    "r, g, b = r[i:i+di]/1e3 + wn[0], g[i:i+di]/1e3 + wn[1], b[i:i+di]/1e3 + wn[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots(3, 1, figsize=(10, 7), sharex=True)\n",
    "ax[0].plot(t, 1+r, '.', color=mpld.red, alpha=1, ms=3.0)\n",
    "ax[1].plot(t, 1+g, '.', color=mpld.green, alpha=1, ms=3.0)\n",
    "ax[2].plot(t, 1+b, '.', color=mpld.blue, alpha=1, ms=3.0)\n",
    "\n",
    "ax[0].annotate('862 nm', xy=(0.85, 0.78), xycoords='axes fraction', fontsize=15)\n",
    "ax[1].annotate('500 nm', xy=(0.85, 0.78), xycoords='axes fraction', fontsize=15)\n",
    "ax[2].annotate('402 nm', xy=(0.85, 0.78), xycoords='axes fraction', fontsize=15)\n",
    "\n",
    "[ax.set_ylim(0.5, 1.5) for ax in ax]\n",
    "ax[2].set_xlabel('days since Jan. 23, 1996')\n",
    "pl.annotate(\"normalized flux\", xy=(0.0, 0.3), \n",
    "            xycoords='figure fraction', \n",
    "            rotation=90, fontsize=30)\n",
    "pl.savefig(\"/Users/tgordon/Desktop/spm_lc.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "\n",
    "def MvUniform(label, lower, upper, **kwargs):\n",
    "    n = len(lower)\n",
    "    lower = tt.as_tensor_variable(lower)\n",
    "    upper = tt.as_tensor_variable(upper)\n",
    "    logp = lambda x: tt.switch(tt.all(x < upper) and tt.all(x > lower), 0, -np.inf)\n",
    "    random = lambda point=None, size=None: lower + np.random.rand(n)*(upper - lower)\n",
    "    return pm.DensityDist(label, logp, random=random, shape=n, **kwargs)\n",
    "\n",
    "class Uniform():\n",
    "    \n",
    "    def __init__(self, name, lower=-np.inf, upper=np.inf, **kwargs):\n",
    "        \n",
    "        self.name = name\n",
    "        self.lower = lower\n",
    "        self.upper = upper \n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def get_dist(self):\n",
    "        \n",
    "        if hasattr(self.lower, \"__len__\"):\n",
    "            return MvUniform(self.name, lower=self.lower, upper=self.upper, **self.kwargs)\n",
    "        else:\n",
    "            return pm.Uniform(self.name, lower=self.lower, upper=self.upper, **self.kwargs)\n",
    "        \n",
    "class Normal():\n",
    "    \n",
    "    def __init__(self, name, mu=0.0, sd=np.inf, **kwargs):\n",
    "        \n",
    "        self.name = name\n",
    "        self.mu = lower\n",
    "        self.se = upper\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    def get_dist(self):\n",
    "        \n",
    "        if hasattr(self.lower, \"__len__\"):\n",
    "            return pm.MvNormal(self.name, mu=self.mu, sd=self.sd, **self.kwargs)\n",
    "        else:\n",
    "            return pm.Normal(self.name, mu=self.mu, sd=self.sd, **self.kwargs)\n",
    "\n",
    "params = {\"logw\": Uniform(\"logw\", lower=[-3, 5, 7], upper=[1, 7, 10], testval=[-1, 6.5, 7.5]), \n",
    "         \"logQ\": Uniform(\"logQ\", lower=0.0, upper=3.0, testval=1.5),\n",
    "         \"logS0\": Uniform(\"logS0\", lower=[-20]*3, upper=[0.0]*3, testval=[-6, -15, -17]),\n",
    "         \"ldg\": Uniform(\"ldg\", lower=[0]*3, upper=[2]*3, testval=[0.5]*3),\n",
    "         \"ldb\": Uniform(\"ldb\", lower=[0]*3, upper=[2]*3, testval=[0.5]*3),\n",
    "         \"mean\": Uniform(\"mean\", lower=[-1]*3, upper=[1]*3, testval=tt.mean([r, g, b], axis=1)),\n",
    "         \"logsig\": Uniform(\"logsig\", lower=[-15]*3, upper=[0.0]*3, testval=[-4]*3)}\n",
    "\n",
    "def find_map_soln(r, g, b, mcmc=False, n_minimizations=1):\n",
    "    y = np.vstack((r, g, b)).T.reshape(3*len(t),)\n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        \n",
    "        for k, v in params.items():\n",
    "            setattr(model, k, v.get_dist())\n",
    "                \n",
    "        term0 = xo.gp.terms.SHOTerm(\n",
    "            log_S0 = model.logS0[0],\n",
    "            log_w0 = model.logw[0],\n",
    "            log_Q = -np.log(np.sqrt(2))\n",
    "        )\n",
    "        term1 = xo.gp.terms.SHOTerm(\n",
    "            log_S0 = model.logS0[1],\n",
    "            log_w0 = model.logw[1],\n",
    "            log_Q = -np.log(np.sqrt(2))\n",
    "        )\n",
    "        term2 = xo.gp.terms.SHOTerm(\n",
    "            log_S0 = model.logS0[2],\n",
    "            log_w0 = model.logw[2],\n",
    "            log_Q = model.logQ\n",
    "        )\n",
    "        \n",
    "        q0 = tt.exp(tt.stack([0.0, model.ldg[0], model.ldb[0]]))\n",
    "        q1 = tt.exp(tt.stack([0.0, model.ldg[1], model.ldb[1]]))\n",
    "        q2 = tt.exp(tt.stack([0.0, model.ldg[2], model.ldb[2]]))\n",
    "        \n",
    "        kernel = (xo.gp.terms.KroneckerTerm(term0, q0) + \n",
    "                  xo.gp.terms.KroneckerTerm(term1, q1) + \n",
    "                  xo.gp.terms.KroneckerTerm(term2, q2))\n",
    "        \n",
    "        yerr = tt.exp(2 * model.logsig)\n",
    "        yerr = yerr[:, None] * tt.ones(len(t))\n",
    "        \n",
    "        mean = model.mean[:, None] * tt.ones(len(t))\n",
    "        mean = tt.reshape(mean.T, (3*len(t),))\n",
    "        \n",
    "        gp = xo.gp.GP(kernel, t, yerr, J=6)\n",
    "        pm.Potential(\"loglike\", gp.log_likelihood(y - mean))\n",
    "        \n",
    "        start = model.test_point\n",
    "        map_soln = None\n",
    "        for i in range(n_minimizations):\n",
    "            map_soln = xo.optimize(start=start, verbose=True)\n",
    "            start = map_soln\n",
    "        if mcmc:\n",
    "            trace = pm.sample(\n",
    "                tune=1000,\n",
    "                draws=1000,\n",
    "                start=start,\n",
    "                cores=2,\n",
    "                chains=2,\n",
    "                step=xo.get_dense_nuts_step(target_accept=0.9)\n",
    "            )\n",
    "            return model, map_soln, trace\n",
    "        else:\n",
    "            return model, map_soln, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, map_soln, trace = find_map_soln(r, g, b, mcmc=True, n_minimizations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_soln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel(d):\n",
    "    \n",
    "    logw = d[\"logw\"]\n",
    "    logQ = d[\"logQ\"]\n",
    "    logS0 = d[\"logS0\"]\n",
    "    ldg = d[\"ldg\"]\n",
    "    ldb = d[\"ldb\"]\n",
    "    \n",
    "    term0 = xo.gp.terms.SHOTerm(\n",
    "            log_S0 = logS0[0],\n",
    "            log_w0 = logw[0],\n",
    "            log_Q = -np.log(np.sqrt(2))\n",
    "    )\n",
    "    term1 = xo.gp.terms.SHOTerm(\n",
    "            log_S0 = logS0[1],\n",
    "            log_w0 = logw[1],\n",
    "            log_Q = -np.log(np.sqrt(2))\n",
    "    )\n",
    "    term2 = xo.gp.terms.SHOTerm(\n",
    "            log_S0 = logS0[2],\n",
    "            log_w0 = logw[2],\n",
    "            log_Q = logQ\n",
    "    )\n",
    "\n",
    "    q0 = tt.exp(tt.stack([0.0, ldg[0], ldb[0]]))\n",
    "    q1 = tt.exp(tt.stack([0.0, ldg[1], ldb[1]]))\n",
    "    q2 = tt.exp(tt.stack([0.0, ldg[2], ldb[2]]))\n",
    "                \n",
    "    kernel = (xo.gp.terms.KroneckerTerm(term0, q0) + \n",
    "              xo.gp.terms.KroneckerTerm(term1, q1) + \n",
    "              xo.gp.terms.KroneckerTerm(term2, q2))\n",
    "                \n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.fft.rfftfreq(len(t), t[1] - t[0])\n",
    "fftr = np.fft.rfft(r)\n",
    "fftg = np.fft.rfft(g)\n",
    "fftb = np.fft.rfft(b)\n",
    "\n",
    "fftr *= np.conj(fftr)\n",
    "fftg *= np.conj(fftg)\n",
    "fftb *= np.conj(fftb)\n",
    "\n",
    "powerfftr = fftr.real / len(t)**2\n",
    "powerfftg = fftg.real / len(t)**2\n",
    "powerfftb = fftb.real / len(t)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = get_kernel(map_soln)\n",
    "psd = kernel.psd(2*np.pi*f).T.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots(3, 1, figsize=(10, 10), sharex=True)\n",
    "ax[0].loglog(f, powerfftr, '.', color=mpld.red)\n",
    "ax[1].loglog(f, powerfftg, '.', color=mpld.green)\n",
    "ax[2].loglog(f, powerfftb, '.', color=mpld.blue)\n",
    "\n",
    "ax[0].loglog(f, psd[0], color='k', linewidth=0.8)\n",
    "ax[1].loglog(f, psd[1], color='k', linewidth=0.8)\n",
    "ax[2].loglog(f, psd[2], color='k', linewidth=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 3\n",
    "gp = xo.gp.GP(kernel, t, np.exp(-10)*np.ones((m, len(t))) ** 2, J=6)\n",
    "z = gp.dot_l(np.random.randn(m*len(t), 1)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots(3, 1, figsize=(10, 7), sharex=True)\n",
    "ax[0].plot(t, 1+z[::3], '.', color=mpld.red, alpha=1, ms=3.0)\n",
    "ax[1].plot(t, 1+z[1::3], '.', color=mpld.green, alpha=1, ms=3.0)\n",
    "ax[2].plot(t, 1+z[2::3], '.', color=mpld.blue, alpha=1, ms=3.0)\n",
    "\n",
    "ax[0].annotate('862 nm', xy=(0.85, 0.78), xycoords='axes fraction', fontsize=15)\n",
    "ax[1].annotate('500 nm', xy=(0.85, 0.78), xycoords='axes fraction', fontsize=15)\n",
    "ax[2].annotate('402 nm', xy=(0.85, 0.78), xycoords='axes fraction', fontsize=15)\n",
    "\n",
    "[ax.set_ylim(0.5, 1.5) for ax in ax]\n",
    "ax[2].set_xlabel('days since Jan. 23, 1996')\n",
    "pl.annotate(\"normalized flux\", xy=(0.0, 0.3), \n",
    "            xycoords='figure fraction', \n",
    "            rotation=90, fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "samples = pm.trace_to_dataframe(trace)\n",
    "_ = corner.corner(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pm.trace_to_dataframe(trace, varnames=['mean', \n",
    "                                                'logw', \n",
    "                                                'logQ',\n",
    "                                                'logS0',\n",
    "                                                'ldg', \n",
    "                                                'ldb', \n",
    "                                                'logsig'])\n",
    "_ = corner.corner(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [np.random.randint(len(trace)) for n in range(10)]\n",
    "kernels = [get_kernel(trace[s]) for s in s]\n",
    "psds = [k.psd(2*np.pi*f).T.eval() for k in kernels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots(3, 1, figsize=(10, 10), sharex=True)\n",
    "ax[0].loglog(f, powerfftr, '.', color=mpld.red)\n",
    "ax[1].loglog(f, powerfftg, '.', color=mpld.green)\n",
    "ax[2].loglog(f, powerfftb, '.', color=mpld.blue)\n",
    "\n",
    "for psd in psds:\n",
    "    ax[0].loglog(f, psd[0], color='k', linewidth=0.8)\n",
    "    ax[1].loglog(f, psd[1], color='k', linewidth=0.8)\n",
    "    ax[2].loglog(f, psd[2], color='k', linewidth=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 3\n",
    "gp = xo.gp.GP(kernels[2], t, np.exp(-10)*np.ones((m, len(t))) ** 2, J=6)\n",
    "z = gp.dot_l(np.random.randn(m*len(t), 1)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots(3, 1, figsize=(10, 7), sharex=True)\n",
    "ax[0].plot(t, 1+z[::3], '.', color=mpld.red, alpha=1, ms=3.0)\n",
    "ax[1].plot(t, 1+z[1::3], '.', color=mpld.green, alpha=1, ms=3.0)\n",
    "ax[2].plot(t, 1+z[2::3], '.', color=mpld.blue, alpha=1, ms=3.0)\n",
    "\n",
    "ax[0].annotate('band A', xy=(0.85, 0.78), xycoords='axes fraction', fontsize=15)\n",
    "ax[1].annotate('band B', xy=(0.85, 0.78), xycoords='axes fraction', fontsize=15)\n",
    "ax[2].annotate('band C', xy=(0.85, 0.78), xycoords='axes fraction', fontsize=15)\n",
    "\n",
    "ax[0].set_title(\"GP sample\")\n",
    "\n",
    "[ax.set_ylim(0.5, 1.5) for ax in ax]\n",
    "ax[2].set_xlabel('days since Jan. 23, 1996')\n",
    "pl.annotate(\"normalized flux\", xy=(0.0, 0.3), \n",
    "            xycoords='figure fraction', \n",
    "            rotation=90, fontsize=30)\n",
    "pl.savefig(\"/Users/tgordon/Desktop/sample.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots(3, 1, figsize=(10, 7), sharex=True)\n",
    "ax[0].plot(t, 1+r, '.', color=mpld.red, alpha=1, ms=3.0)\n",
    "ax[1].plot(t, 1+g, '.', color=mpld.green, alpha=1, ms=3.0)\n",
    "ax[2].plot(t, 1+b, '.', color=mpld.blue, alpha=1, ms=3.0)\n",
    "\n",
    "ax[0].annotate('862 nm', xy=(0.85, 0.78), xycoords='axes fraction', fontsize=15)\n",
    "ax[1].annotate('500 nm', xy=(0.85, 0.78), xycoords='axes fraction', fontsize=15)\n",
    "ax[2].annotate('402 nm', xy=(0.85, 0.78), xycoords='axes fraction', fontsize=15)\n",
    "\n",
    "ax[0].set_title(\"SOHO observations\")\n",
    "\n",
    "[ax.set_ylim(0.5, 1.5) for ax in ax]\n",
    "ax[2].set_xlabel('days since Jan. 23, 1996')\n",
    "pl.annotate(\"normalized flux\", xy=(0.0, 0.3), \n",
    "            xycoords='figure fraction', \n",
    "            rotation=90, fontsize=30)\n",
    "pl.savefig(\"/Users/tgordon/Desktop/spm_lc.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pm.stats.ess(trace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.log(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([r, g, b], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tt.as_tensor_variable([1, 2, 3])\n",
    "m = m[:, None] * np.ones(10)\n",
    "tt.reshape(m.T, (30,)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    #setattr(model, \"x\", pm.Uniform(\"x\", lower=0, upper=1))\n",
    "    x = pm.Uniform(\"x\", lower=0, upper=1)\n",
    "    x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
